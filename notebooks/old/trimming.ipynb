{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QTI1gR7HRvC"
   },
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nadZT9MIaBU"
   },
   "outputs": [],
   "source": [
    "# upload kaggle json\n",
    " ! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xvXzvA1Inlg"
   },
   "outputs": [],
   "source": [
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSn8EF9bIpwE"
   },
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mayKFXNxIrWI",
    "outputId": "d7127c8a-8d8c-400a-c603-c4c9e017194b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading redditrplacecsv.zip to /content\n",
      "100% 11.6G/11.6G [01:22<00:00, 201MB/s]\n",
      "100% 11.6G/11.6G [01:22<00:00, 151MB/s]\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d antoinecarpentier/redditrplacecsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVETHHjtIsq8",
    "outputId": "dae96fef-cad4-49c7-a2e8-89885b83fd86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  redditrplacecsv.zip\n",
      "  inflating: 2022_place_canvas_history.csv  \n"
     ]
    }
   ],
   "source": [
    "! unzip redditrplacecsv.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a6yG1QG4JBCf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdMZWlGMJFND",
    "outputId": "968e50a5-70f3-413d-c594-dc50c5956e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-694"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# The length of time in milliseconds after 1970-01-01T00:00:00.000 UTC that\n",
    "# the first pixel was placed in r/Place 2022.\n",
    "#START_TIME = 1648806250315 #begin of place in ms\n",
    "#START_TIME = 1648806250.315 #begin of place in s\n",
    "#START_TIME = 1648806250 #begin of place in s INT\n",
    "START_TIME  = 1648806250\n",
    "\n",
    "def parse_timestamp(timestamp):\n",
    "    \"\"\"Convert a YYYY-MM-DD HH:MM:SS.SSS timestamp to milliseconds after the start of r/Place 2022.\"\"\"\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    try:\n",
    "        # Remove the UTC timezone from the timestamp and convert it to a POSIX timestamp.\n",
    "        timestamp = datetime.strptime(timestamp[:-4], date_format).timestamp()\n",
    "    except ValueError:\n",
    "        # The timestamp is exactly on the second, so there is no decimal (%f).\n",
    "        # This happens 1/1000 of the time.\n",
    "        timestamp = datetime.strptime(timestamp[:-4], date_format[:-3]).timestamp()\n",
    "\n",
    "    # Convert from a float in seconds to an int in milliseconds\n",
    "    #timestamp *= 1000.0\n",
    "    #timestamp = int(timestamp)\n",
    "\n",
    "    # The earliest timestamp is 1648806250315, so subtract that from each timestamp\n",
    "    # to get the time in milliseconds since the beginning of the experiment.\n",
    "    timestamp = timestamp -  START_TIME\n",
    "    timestamp = float(timestamp) / 60.\n",
    "    timestamp = int(timestamp)\n",
    "    return timestamp\n",
    "\n",
    "\n",
    "# Parse a sample timestamp.\n",
    "parse_timestamp(\"2022-04-01 00:09:44.375 UTC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEGIN = \"2022-04-05 00:53:51.577 UTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_format = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "\n",
    "int((datetime.strptime(BEGIN[:-4], date_format).timestamp() - START_TIME ) / 60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_timestamp(BEGIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2022, 4, 1, 9, 44, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tWzWM4TyJJKT"
   },
   "outputs": [],
   "source": [
    "def parse_pixel_color(pixel_color):\n",
    "    \"\"\"Convert a hex color code to an integer key.\"\"\"\n",
    "    hex_to_key = {\n",
    "        \"#000000\": 0,\n",
    "        \"#00756F\": 1,\n",
    "        \"#009EAA\": 2,\n",
    "        \"#00A368\": 3,\n",
    "        \"#00CC78\": 4,\n",
    "        \"#00CCC0\": 5,\n",
    "        \"#2450A4\": 6,\n",
    "        \"#3690EA\": 7,\n",
    "        \"#493AC1\": 8,\n",
    "        \"#515252\": 9,\n",
    "        \"#51E9F4\": 10,\n",
    "        \"#6A5CFF\": 11,\n",
    "        \"#6D001A\": 12,\n",
    "        \"#6D482F\": 13,\n",
    "        \"#7EED56\": 14,\n",
    "        \"#811E9F\": 15,\n",
    "        \"#898D90\": 16,\n",
    "        \"#94B3FF\": 17,\n",
    "        \"#9C6926\": 18,\n",
    "        \"#B44AC0\": 19,\n",
    "        \"#BE0039\": 20,\n",
    "        \"#D4D7D9\": 21,\n",
    "        \"#DE107F\": 22,\n",
    "        \"#E4ABFF\": 23,\n",
    "        \"#FF3881\": 24,\n",
    "        \"#FF4500\": 25,\n",
    "        \"#FF99AA\": 26,\n",
    "        \"#FFA800\": 27,\n",
    "        \"#FFB470\": 28,\n",
    "        \"#FFD635\": 29,\n",
    "        \"#FFF8B8\": 30,\n",
    "        \"#FFFFFF\": 31,\n",
    "    }\n",
    "\n",
    "    return hex_to_key[pixel_color]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jahvbSOfJLY3"
   },
   "outputs": [],
   "source": [
    "def split_coords_single_points(points):\n",
    "    \"\"\"\n",
    "    Given a dataframe containing only rows that have single-point\n",
    "    coordinates, split the coordinates into x and y columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the coordinate column to a list of strings.\n",
    "    points[\"coordinate\"] = points[\"coordinate\"].apply(lambda x: x.split(\",\"))\n",
    "\n",
    "    # Create new x and y columns from the coordinate column.\n",
    "    points[\"x\"] = points[\"coordinate\"].apply(lambda x: x[0]).astype(\"uint16\")\n",
    "    points[\"y\"] = points[\"coordinate\"].apply(lambda x: x[1]).astype(\"uint16\")\n",
    "\n",
    "    # Drop the coordinate column.\n",
    "    del points[\"coordinate\"]\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uCLC9bfGJPBt"
   },
   "outputs": [],
   "source": [
    "def process_chunk(chunk, df,counter,mapping):\n",
    "    chunk[\"timestamp\"] = chunk[\"timestamp\"].astype(\"uint16\")\n",
    "    chunk[\"pixel_color\"] = chunk[\"pixel_color\"].astype(\"uint8\")\n",
    "    \n",
    "    # per rimuovere le azioni degli admin\n",
    "    chunk.drop(chunk[chunk[\"coordinate\"].str.count(\",\") == 3].index,inplace=True)\n",
    "\n",
    "    chunk = split_coords_single_points(chunk)\n",
    "    \n",
    "    for user in chunk.user_id:\n",
    "        if not user in mapping:\n",
    "            mapping[user] = counter\n",
    "            counter += 1\n",
    "\n",
    "    chunk[\"user_id\"] = chunk[\"user_id\"].map(mapping)\n",
    "    chunk[\"user_id\"] = chunk[\"user_id\"].astype(\"uint32\")\n",
    "\n",
    "    df = pd.concat((df, chunk), ignore_index=True)\n",
    "\n",
    "    return df,counter,mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qsaMmEJcJR6_"
   },
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 1000000\n",
    "\n",
    "def trim(infile_path, outfile_path):\n",
    "    \"\"\"Trim the infile data and write it to outfile.\"\"\"\n",
    "    df = pd.DataFrame(columns=[\"timestamp\", \"user_id\",\"pixel_color\", \"x\", \"y\"])\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].astype(\"uint32\")\n",
    "    df[\"pixel_color\"] = df[\"pixel_color\"].astype(\"uint8\")\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(\"uint32\")\n",
    "\n",
    "    df[\"x\"] = df[\"x\"].astype(\"uint16\")\n",
    "    df[\"y\"] = df[\"y\"].astype(\"uint16\")\n",
    "\n",
    "    mapping = {}\n",
    "    counter = 0\n",
    "    \n",
    "    with pd.read_csv(\n",
    "        infile_path,\n",
    "        usecols=[\"timestamp\", \"user_id\",\"pixel_color\", \"coordinate\"],\n",
    "        converters={\n",
    "            \"timestamp\": parse_timestamp,\n",
    "            \"pixel_color\": parse_pixel_color,\n",
    "        },\n",
    "        chunksize=CHUNK_SIZE,\n",
    "        engine=\"c\",\n",
    "        #compression=\"gzip\",\n",
    "    ) as csv:\n",
    "        for chunk in tqdm(csv):\n",
    "            df, counter, mapping = process_chunk(chunk, df,counter,mapping)\n",
    "            df.sort_values(\"timestamp\", inplace=True, ignore_index=True)    \n",
    "    print(counter)\n",
    "    df.to_csv(outfile_path, sep=',', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_path = \"2022_place_canvas_history.csv\"\n",
    "outfile_path = \"reddit_trimmed.csv\" \n",
    "\n",
    "df_trim = trim(infile_path, outfile_path)\n",
    "df_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# versione 2 salvando chunk singoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk_v2(chunk,counter,mapping):\n",
    "    chunk[\"timestamp\"] = chunk[\"timestamp\"].astype(\"uint16\")\n",
    "    chunk[\"pixel_color\"] = chunk[\"pixel_color\"].astype(\"uint8\")\n",
    "    \n",
    "    # per rimuovere le azioni degli admin\n",
    "    chunk.drop(chunk[chunk[\"coordinate\"].str.count(\",\") == 3].index,inplace=True)\n",
    "\n",
    "    chunk = split_coords_single_points(chunk)\n",
    "    \n",
    "    for user in chunk.user_id:\n",
    "        if not user in mapping:\n",
    "            mapping[user] = counter\n",
    "            counter += 1\n",
    "\n",
    "    chunk[\"user_id\"] = chunk[\"user_id\"].map(mapping)\n",
    "    chunk[\"user_id\"] = chunk[\"user_id\"].astype(\"uint32\")\n",
    "\n",
    "\n",
    "    return chunk,counter,mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 5000000\n",
    "#CHUNK_SIZE = 200\n",
    "\n",
    "\n",
    "def trim_v2(infile_path, outfile_path):\n",
    "    \"\"\"Trim the infile data and write it to outfile.\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"timestamp\", \"user_id\",\"pixel_color\", \"x\", \"y\"])\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].astype(\"uint16\")\n",
    "    df[\"pixel_color\"] = df[\"pixel_color\"].astype(\"uint8\")\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(\"uint32\")\n",
    "\n",
    "    df[\"x\"] = df[\"x\"].astype(\"uint16\")\n",
    "    df[\"y\"] = df[\"y\"].astype(\"uint16\")\n",
    "\n",
    "    mapping = {}\n",
    "    counter = 0\n",
    "    header = True # FONDAMENTALE\n",
    "    with pd.read_csv(\n",
    "        infile_path,\n",
    "        usecols=[\"timestamp\", \"user_id\",\"pixel_color\", \"coordinate\"],\n",
    "        converters={\n",
    "            \"timestamp\": parse_timestamp,\n",
    "            \"pixel_color\": parse_pixel_color,\n",
    "        },\n",
    "        chunksize=CHUNK_SIZE,\n",
    "        engine=\"c\",\n",
    "        #compression=\"gzip\",\n",
    "    ) as csv:\n",
    "        for chunk in tqdm(csv):\n",
    "            df, counter, mapping = process_chunk_v2(chunk,counter,mapping)\n",
    "            df.sort_values(\"timestamp\", inplace=True, ignore_index=True)\n",
    "            if header:\n",
    "                df.to_csv(outfile_path,header=header, mode='w', index = False)\n",
    "                header = False\n",
    "            else:\n",
    "                df.to_csv(outfile_path,header=header, mode='a', index = False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_path = \"data/2022_place_canvas_history.csv\"\n",
    "outfile_path = \"output/reddit_trimmed_v2_minutes.csv\" \n",
    "\n",
    "df_trim = trim_v2(infile_path, outfile_path)\n",
    "df_trim.timestamp"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "trimming.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
